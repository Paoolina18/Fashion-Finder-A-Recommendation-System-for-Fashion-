{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76d694ad-1f35-4071-9fd1-2bc684c7e6e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2663353219.py, line 647)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 647\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31moutfits generados\u001b[39m\n            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "\n",
    "\n",
    "multiple_users= True\n",
    "# üîß Evaluaci√≥n de prendas de la marca By Paola Ospina\n",
    "evaluar_marca = True # üîÅ Cambia a False para desactivar esta l√≥gica\n",
    "marca_objetivo = \"By Paola Ospina\"\n",
    "\n",
    "def inicializar_sistema(multiple_users=False):\n",
    "    \"\"\"\n",
    "    Inicializa el sistema de FashionIA:\n",
    "    - Pide el nombre del usuario si multiple_users est√° activo\n",
    "    - Crea carpetas y archivos necesarios\n",
    "    - Carga im√°genes, categor√≠as, feedback y Q-table\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    global username, user_folder, category_file, feedback_dir, q_table_path\n",
    "    global df, feedback_db, q_table\n",
    "    global ruta_kpis, ruta_dashboard, ruta_imagen, ruta_feedback_csv\n",
    "    global param_file\n",
    "\n",
    "\n",
    "    # 1. Definir usuario\n",
    "    username = input(\"üîê Ingrese el nombre del usuario: \").strip().lower() if multiple_users else \"pao\"\n",
    "\n",
    "    # 2. Rutas del usuario\n",
    "    base_path = r\"C:\\Users\\POspina\\OneDrive - SLB\\Desktop\\Backup\\Tesis\\Closet\"\n",
    "    user_path = os.path.join(base_path, username)\n",
    "    user_folder = os.path.join(user_path, \"Fotos\")\n",
    "    category_file = os.path.join(user_path, f\"categorias_{username}.xlsx\")\n",
    "    feedback_dir = os.path.join(user_path, \"Feedback\")\n",
    "    q_table_path = os.path.join(user_path, \"q_table.xlsx\")\n",
    "    param_file = os.path.join(user_path, \"params.json\")  # üìå Archivo de par√°metros por usuario\n",
    "    ruta_kpis = os.path.join(user_path, \"kpis.xlsx\")\n",
    "    ruta_dashboard = os.path.join(user_path, \"dashboard.xlsx\")\n",
    "    ruta_imagen = os.path.join(user_path, \"curva_aprendizaje.png\")\n",
    "    ruta_feedback_csv = os.path.join(feedback_dir, \"feedback.csv\")\n",
    "    q_table_path = os.path.join(user_path, \"q_table.xlsx\")\n",
    "    \n",
    "        \n",
    "    # 3. Crear carpetas si no existen\n",
    "    os.makedirs(user_folder, exist_ok=True)\n",
    "    os.makedirs(feedback_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "    # 3.5 Cargar o inicializar par√°metros de aprendizaje\n",
    "    default_params = {\"alpha\": 0.1, \"gamma\": 0.9, \"epsilon\": 1.0, \"decay_rate\": 0.995}\n",
    "    if os.path.exists(param_file):\n",
    "        with open(param_file, 'r') as f:\n",
    "            params = json.load(f)\n",
    "        print(\"üîÅ Par√°metros de aprendizaje cargados desde archivo.\")\n",
    "    else:\n",
    "        params = default_params\n",
    "        with open(param_file, 'w') as f:\n",
    "            json.dump(params, f)\n",
    "        print(\"üÜï Archivo de par√°metros creado con valores por defecto.\")\n",
    "    \n",
    "    # Asignar a variables globales\n",
    "    global alpha, gamma, epsilon, decay_rate\n",
    "    alpha = params[\"alpha\"]\n",
    "    gamma = params[\"gamma\"]\n",
    "    epsilon = params[\"epsilon\"]\n",
    "    decay_rate = params[\"decay_rate\"]\n",
    "\n",
    "\n",
    "    # 4. Crear archivo de categor√≠as si no existe\n",
    "    CATEGORY_COLUMNS = [\"Image_ID\", \"Type\", \"Color\", \"Weather\", \"Style\", \"Occasion\"]\n",
    "    if not os.path.exists(category_file):\n",
    "        pd.DataFrame(columns=CATEGORY_COLUMNS).to_excel(category_file, index=False)\n",
    "        print(f\"üìÇ Archivo de categor√≠as creado: {category_file}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Archivo de categor√≠as encontrado: {category_file}\")\n",
    "\n",
    "\n",
    "    # 5. Cargar im√°genes y categor√≠as\n",
    "    def create_dataframe(folder):\n",
    "        data = []\n",
    "        for file in os.listdir(folder):\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                try:\n",
    "                    image_id = int(os.path.splitext(file)[0])\n",
    "                    file_path = os.path.join(folder, file)\n",
    "                    data.append({'Image_ID': image_id, 'Image': file_path})\n",
    "                except ValueError:\n",
    "                    print(f\"‚ö†Ô∏è Archivo inv√°lido: {file}\")\n",
    "        return pd.DataFrame(data).sort_values(\"Image_ID\").reset_index(drop=True)\n",
    "\n",
    "    def load_categories(file):\n",
    "        try:\n",
    "            return pd.read_excel(file)\n",
    "        except:\n",
    "            print(\"‚ùå No se pudo cargar el archivo de categor√≠as.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    df_images = create_dataframe(user_folder)\n",
    "    df_categories = load_categories(category_file)\n",
    "    \n",
    "    if \"Image\" in df_categories.columns:\n",
    "        df_categories = df_categories.drop(columns=[\"Image\"])\n",
    "        # Asegurarse de que 'Image' se construya correctamente desde 'Image_ID'\n",
    "    df_categories[\"Image\"] = df_categories[\"Image_ID\"].apply(\n",
    "        lambda x: os.path.join(user_folder, f\"{x}.jpg\")\n",
    "    ) \n",
    "\n",
    "    if df_images.empty or df_categories.empty:\n",
    "        print(\"‚ùå Error: faltan im√°genes o categor√≠as.\")\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        # Construir la ruta de la imagen directamente desde el Image_ID\n",
    "        df = df_categories.copy()\n",
    "        df[\"Image\"] = df[\"Image_ID\"].apply(lambda x: os.path.join(user_folder, f\"{x}.jpg\"))\n",
    "        \n",
    "        # Rellenar campos faltantes y asegurar columna Weight\n",
    "        df.fillna({\n",
    "            \"Type\": \"Unknown\",\n",
    "            \"Color\": \"Unknown\",\n",
    "            \"Weather\": \"All\",\n",
    "            \"Style\": \"Casual\",\n",
    "            \"Occasion\": \"Any\"\n",
    "        }, inplace=True)\n",
    "        \n",
    "        if 'Weight' not in df.columns:\n",
    "            df['Weight'] = 0.0\n",
    "\n",
    "        print(f\"‚úÖ {len(df)} prendas cargadas para el usuario '{username}'\")\n",
    "\n",
    "    # 6. Cargar feedback hist√≥rico\n",
    "    feedback_db = []\n",
    "    feedback_files = glob.glob(os.path.join(feedback_dir, \"feedback_*.csv\"))\n",
    "    if feedback_files:\n",
    "        dfs = [pd.read_csv(f) for f in feedback_files]\n",
    "        feedback_hist = pd.concat(dfs, ignore_index=True)\n",
    "        feedback_hist.drop_duplicates(subset=[\"Outfit_ID\", \"Image_ID\", \"Timestamp\"], inplace=True)\n",
    "        feedback_db = feedback_hist.to_dict('records')\n",
    "        print(f\"üìà Feedback cargado: {len(feedback_db)} entradas.\")\n",
    "    else:\n",
    "        print(\"üì≠ No se encontr√≥ feedback previo.\")\n",
    "\n",
    "    # 7. Cargar Q-table del usuario\n",
    "    q_table = {}\n",
    "    if os.path.exists(q_table_path):\n",
    "        df_qtable = pd.read_excel(q_table_path)\n",
    "        if \"State\" in df_qtable.columns and \"Action\" in df_qtable.columns:\n",
    "            q_table = {(eval(row[\"State\"]), eval(row[\"Action\"])): row[\"Q-Value\"] for _, row in df_qtable.iterrows()}\n",
    "            print(f\"üîÑ Q-Table cargada con {len(q_table)} combinaciones.\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Q-Table con formato incompatible.\")\n",
    "    else:\n",
    "        print(\"üÜï No se encontr√≥ Q-Table previa. Se iniciar√° vac√≠a.\")\n",
    "\n",
    "    print(f\"üöÄ Inicializaci√≥n completa para: {username}\")\n",
    "\n",
    "inicializar_sistema(multiple_users)  # o False si solo usar√°s 'pao'\n",
    "  # üö® Cambia a True para permitir input din√°mico\n",
    "\n",
    "def guardar_feedback(outfit, rewards, fuente=\"Humano\"):\n",
    "    \"\"\"\n",
    "    Guarda el feedback de un outfit en un archivo CSV.\n",
    "    `outfit`: lista de diccionarios con las prendas (cada uno debe tener keys como 'Image_ID', 'Type', 'Brand', 'Color').\n",
    "    `rewards`: lista de enteros (+1 o -1) con el reward para cada prenda.\n",
    "    `fuente`: \"Humano\" o \"IA\"\n",
    "    \"\"\"\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    feedback_file = ruta_feedback_csv\n",
    "\n",
    "    # Si el archivo ya existe, obtenemos el √∫ltimo Outfit_ID\n",
    "    if os.path.exists(feedback_file):\n",
    "        existing_df = pd.read_csv(feedback_file)\n",
    "        last_outfit_id = existing_df[\"Outfit_ID\"].max() + 1\n",
    "    else:\n",
    "        last_outfit_id = 1\n",
    "\n",
    "    # Crear nuevo DataFrame de feedback\n",
    "    data = []\n",
    "    for i, prenda in enumerate(outfit):\n",
    "        fila = {\n",
    "            \"Outfit_ID\": last_outfit_id,\n",
    "            \"Image_ID\": prenda.get(\"Image_ID\"),\n",
    "            \"Type\": prenda.get(\"Type\"),\n",
    "            \"Brand\": prenda.get(\"Brand\"),\n",
    "            \"Color\": prenda.get(\"Color\"),\n",
    "            \"Reward\": rewards[i],\n",
    "            \"Fuente\": fuente,\n",
    "            \"Timestamp\": timestamp\n",
    "        }\n",
    "        data.append(fila)\n",
    "\n",
    "    df_nuevo = pd.DataFrame(data)\n",
    "\n",
    "    # Guardar en modo append para no sobrescribir\n",
    "    df_nuevo.to_csv(feedback_file, mode=\"a\", index=False, header=not os.path.exists(feedback_file))\n",
    "\n",
    "\n",
    "## GUARDAR HIPERPARAMETROS\n",
    "\n",
    "def save_params():\n",
    "    \"\"\"\n",
    "    Guarda los par√°metros de aprendizaje (incluyendo epsilon actualizado) en params.json.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"alpha\": alpha,\n",
    "        \"gamma\": gamma,\n",
    "        \"epsilon\": epsilon,\n",
    "        \"decay_rate\": decay_rate\n",
    "    }\n",
    "    with open(param_file, 'w') as f:\n",
    "        json.dump(params, f)\n",
    "    print(f\"üõ†Ô∏è Par√°metros de aprendizaje guardados: Œµ={epsilon:.4f}\")\n",
    "\n",
    "#########################\n",
    "def get_user_paths(username):\n",
    "    \"\"\"\n",
    "    Devuelve rutas personalizadas basadas en el nombre del usuario.\n",
    "    \"\"\"\n",
    "    base_path = r\"C:\\Users\\POspina\\OneDrive - SLB\\Desktop\\Backup\\Tesis\\Closet\"\n",
    "    user_folder = os.path.join(base_path, username, \"Fotos\")\n",
    "    category_file = os.path.join(base_path, username, f\"categorias_{username}.xlsx\")\n",
    "    return user_folder, category_file\n",
    "## DEFINIR DICCIONARIOS\n",
    "\n",
    "# Diccionarios de codificaci√≥n globales\n",
    "type_encoding = {\"Top\": 0, \"Bottom\": 1, \"Dress\": 2, \"Jacket\": 3, \"Hoodie\": 4}\n",
    "color_encoding = {\"White\": 0, \"Black\": 1, \"Red\": 2, \"Blue\": 3, \"Yellow\": 4, \"Purple\": 5, \n",
    "                  \"Orange\": 6, \"Green\": 7, \"Gray\": 8, \"Rose\": 9, \"Beige\": 10, \"Brown\": 11}\n",
    "style_encoding = {\"Casual\": 0, \"Formal\": 1, \"Elegante\": 2, \"Urbano\": 3}\n",
    "occasion_encoding = {\"Fiesta\": 0, \"Diario\": 1, \"Cena\": 2, \"Trabajo\": 3}\n",
    "weather_encoding = {\"Fr√≠o\": 0, \"C√°lido\": 1, \"Todas\": 2}\n",
    "material_encoding = {\"Lana\": 1, \"Poli√©ster\": 2, \"Seda\": 3, \"Algod√≥n\": 4, \"Cuero\": 5, \"Jean\": 6, \"Licra\": 7, \"Lino\": 8}\n",
    "fit_encoding = {\"Regular\": 1, \"Ajustado\": 2, \"Oversized\": 3}\n",
    "length_encoding = {\"Corto\": 1, \"Largo\": 2, \"Medio\": 3}\n",
    "brand_encoding = {\"Nike\": 1, \"Adidas\": 2, \"Gucci\": 3, \"Todas\": 4}\n",
    "\n",
    "\n",
    "\n",
    "###_____________________________________________________________________\n",
    "def load_categories_from_excel(category_file):\n",
    "    \"\"\"\n",
    "    Carga el archivo de categor√≠as desde Excel y lo devuelve como un DataFrame.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(category_file):\n",
    "        print(f\"üö® Error: No se encontr√≥ el archivo {category_file}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        df_categories = pd.read_excel(category_file)\n",
    "        print(f\"‚úÖ Categor√≠as cargadas exitosamente desde {category_file}\")\n",
    "        return df_categories\n",
    "    except Exception as e:\n",
    "        print(f\"üö® Error al cargar el archivo de categor√≠as: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# üîπ Mueve la definici√≥n de create_dataframe() antes de que se use en create_full_dataframe()\n",
    "def create_dataframe(user_folder):\n",
    "    \"\"\"\n",
    "    Crea un DataFrame con las im√°genes en la carpeta, extrayendo el ID desde el nombre del archivo (ej. '12.jpg').\n",
    "    As√≠ se asegura que coincidan con el 'Image_ID' del Excel.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    for file in os.listdir(user_folder):\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            try:\n",
    "                # Extraer el n√∫mero del nombre del archivo antes de la extensi√≥n\n",
    "                image_id = int(os.path.splitext(file)[0])\n",
    "                file_path = os.path.join(user_folder, file)\n",
    "\n",
    "                data.append({\n",
    "                    'Image_ID': image_id,\n",
    "                    'Image': file_path\n",
    "                })\n",
    "            except ValueError:\n",
    "                print(f\"‚ö†Ô∏è El archivo '{file}' no tiene un nombre num√©rico v√°lido. Se omitir√°.\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.sort_values(\"Image_ID\", inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ahora, cuando se llame a create_full_dataframe(), Python ya conocer√° create_dataframe()\n",
    "def create_full_dataframe(username):\n",
    "    user_folder, category_file = get_user_paths(username)\n",
    "\n",
    "    df_images = create_dataframe(user_folder)  # Cargar im√°genes con 'Image_ID' y 'Image'\n",
    "    df_categories = load_categories_from_excel(category_file)  # Cargar categor√≠as desde el Excel\n",
    "\n",
    "    if df_images.empty:\n",
    "        print(\"üö® No se encontraron im√°genes en la carpeta del usuario.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if df_categories.empty:\n",
    "        print(\"üö® No se encontraron categor√≠as en el archivo Excel.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # üîπ Asegurar que 'Image_ID' est√° presente en ambos DataFrames antes de fusionar\n",
    "    if \"Image_ID\" not in df_categories.columns:\n",
    "        print(\"üö® Error: 'Image_ID' no est√° en el archivo de categor√≠as.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # üîπ Fusionar categor√≠as con im√°genes basadas en 'Image_ID'\n",
    "    df_categories = df_categories.merge(df_images[['Image_ID', 'Image']], on=\"Image_ID\", how=\"left\")\n",
    "\n",
    "    print(f\"üìå Columnas en df despu√©s del merge: {df_categories.columns.tolist()}\")\n",
    "\n",
    "    # üîπ Llenar valores nulos en caso de que alguna prenda no tenga imagen asociada\n",
    "    df_categories.fillna({\"Image\": \"No Image\", \"Type\": \"Unknown\", \"Color\": \"Unknown\", \"Weather\": \"All\", \"Style\": \"Casual\", \"Occasion\": \"Any\"}, inplace=True)\n",
    "\n",
    "    print(f\"‚úÖ Se han cargado {len(df_categories)} prendas en el DataFrame con im√°genes.\")\n",
    "\n",
    "    return df_categories  # Retornar df_categories con la columna 'Image'\n",
    "\n",
    "def estandarizar_marcas(df, marca_objetivo=\"By Paola Ospina\"):\n",
    "    \"\"\"\n",
    "    Limpia la columna 'Brand' y reemplaza variantes por el nombre oficial de la marca.\n",
    "    \"\"\"\n",
    "    import unidecode\n",
    "    df[\"Brand\"] = df[\"Brand\"].astype(str).apply(lambda x: unidecode.unidecode(x.strip().lower()))\n",
    "\n",
    "    df[\"Brand\"] = df[\"Brand\"].apply(\n",
    "        lambda x: marca_objetivo if \"paola\" in x and \"ospina\" in x else x.title()\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "#_________________________________________________________\n",
    "\n",
    "def get_state_vector(image_id, df):\n",
    "    \"\"\"\n",
    "    Genera un vector de estado para el aprendizaje por refuerzo basado en las categor√≠as esenciales y opcionales.\n",
    "    \"\"\"\n",
    "    row = df[df[\"Image_ID\"] == image_id]\n",
    "    if row.empty:\n",
    "        return [0] * 25  # Vector nulo si la imagen no existe (ajustado para el n√∫mero total de caracter√≠sticas)\n",
    "\n",
    "    row = row.iloc[0]  # Obtener la fila correspondiente\n",
    "\n",
    "    # üîπ Representaci√≥n One-Hot Encoding para 'Type'\n",
    "    type_encoding = {\"Top\": 0, \"Bottom\": 1, \"Dress\": 2, \"Jacket\": 3, \"Hoodie\": 4}\n",
    "    type_vector = [0] * len(type_encoding)\n",
    "    if row[\"Type\"] in type_encoding:\n",
    "        type_vector[type_encoding[row[\"Type\"]]] = 1\n",
    "\n",
    "    # üîπ Representaci√≥n One-Hot Encoding para 'Color' (puede contener m√∫ltiples valores separados por comas)\n",
    "    color_encoding = {\"White\": 0, \"Black\": 1, \"Red\": 2, \"Blue\": 3, \"Yellow\": 4, \"Purple\": 5, \n",
    "                      \"Orange\": 6, \"Green\": 7, \"Gray\": 8, \"Rose\": 9, \"Beige\": 10, \"Brown\": 11}\n",
    "    color_vector = [0] * len(color_encoding)\n",
    "    for color in row[\"Color\"].split(\", \"):\n",
    "        if color in color_encoding:\n",
    "            color_vector[color_encoding[color]] = 1\n",
    "\n",
    "    # üîπ Representaci√≥n One-Hot Encoding para 'Style'\n",
    "    style_encoding = {\"Casual\": 0, \"Formal\": 1, \"Elegante\": 2, \"Urbano\": 3}\n",
    "    style_vector = [0] * len(style_encoding)\n",
    "    for style in row[\"Style\"].split(\", \"):\n",
    "        if style in style_encoding:\n",
    "            style_vector[style_encoding[style]] = 1\n",
    "\n",
    "    # üîπ Representaci√≥n One-Hot Encoding para 'Occasion'\n",
    "    occasion_encoding = {\"Fiesta\": 0, \"Diario\": 1, \"Cena\": 2, \"Trabajo\": 3}\n",
    "    occasion_vector = [0] * len(occasion_encoding)\n",
    "    for occasion in row[\"Occasion\"].split(\", \"):\n",
    "        if occasion in occasion_encoding:\n",
    "            occasion_vector[occasion_encoding[occasion]] = 1\n",
    "\n",
    "    # üîπ Representaci√≥n One-Hot Encoding para 'Weather'\n",
    "    weather_encoding = {\"Fr√≠o\": 0, \"C√°lido\": 1, \"Todas\": 2}\n",
    "    weather_vector = [0] * len(weather_encoding)\n",
    "    for weather in row[\"Weather\"].split(\", \"):\n",
    "        if weather in weather_encoding:\n",
    "            weather_vector[weather_encoding[weather]] = 1\n",
    "\n",
    "    # üîπ Agregar caracter√≠sticas opcionales (Material, Fit, Length, Brand con mapeo b√°sico)\n",
    "    material_encoding = {\"Lana\": 1, \"Poli√©ster\": 2, \"Seda\": 3, \"Algod√≥n\": 4,\"Cuero\": 5,\"Jean\": 6,\"Licra\": 7,\"Lino\": 8}\n",
    "    fit_encoding = {\"Regular\": 1, \"Ajustado\": 2, \"Oversized\": 3}\n",
    "    length_encoding = {\"Corto\": 1, \"Largo\": 2, \"Medio\": 3}\n",
    "    brand_encoding = {\"Nike\": 1, \"Adidas\": 2, \"Gucci\": 3, \"Todas\": 4}\n",
    "\n",
    "    material = material_encoding.get(row[\"Material\"], 0)\n",
    "    fit = fit_encoding.get(row[\"Fit\"], 0)\n",
    "    length = length_encoding.get(row[\"Length\"], 0)\n",
    "    brand = brand_encoding.get(row[\"Brand\"], 0)\n",
    "\n",
    "    # üîπ Agregar peso de la prenda\n",
    "    weight = row[\"Weight\"] if \"Weight\" in row else 0.0\n",
    "\n",
    "    # üîπ Concatenar todo en un solo vector\n",
    "    return type_vector + color_vector + style_vector + occasion_vector + weather_vector + [material, fit, length, brand, weight]\n",
    "\n",
    "import unidecode  #pip install unidecode\n",
    "\n",
    "def actualizar_diccionarios(df):\n",
    "    \"\"\"\n",
    "    Revisa si hay nuevas etiquetas en las categor√≠as que no est√°n en los diccionarios.\n",
    "    Si encuentra nuevas, las agrega autom√°ticamente.\n",
    "    Normaliza may√∫sculas y tildes para la comparaci√≥n.\n",
    "    \"\"\"\n",
    "    import unidecode\n",
    "\n",
    "    global type_encoding, color_encoding, style_encoding, occasion_encoding, weather_encoding\n",
    "    global material_encoding, fit_encoding, length_encoding, brand_encoding\n",
    "\n",
    "    diccionarios = {\n",
    "        'Type': type_encoding,\n",
    "        'Color': color_encoding,\n",
    "        'Style': style_encoding,\n",
    "        'Occasion': occasion_encoding,\n",
    "        'Weather': weather_encoding,\n",
    "        'Material': material_encoding,\n",
    "        'Fit': fit_encoding,\n",
    "        'Length': length_encoding,\n",
    "        'Brand': brand_encoding\n",
    "    }\n",
    "\n",
    "    for categoria, encoding in diccionarios.items():\n",
    "        print(f\"\\nüîç Revisando categor√≠a: {categoria}\")\n",
    "        valores = df[categoria].dropna().unique()\n",
    "\n",
    "        for val in valores:\n",
    "            subvalores = str(val).split(\", \")\n",
    "            for subvalor in subvalores:\n",
    "                normalizado = unidecode.unidecode(subvalor.strip().lower())\n",
    "                claves_normalizadas = [unidecode.unidecode(k.lower()) for k in encoding.keys()]\n",
    "                if normalizado not in claves_normalizadas:\n",
    "                    nuevo_index = max(encoding.values(), default=-1) + 1\n",
    "                    encoding[subvalor.strip()] = nuevo_index\n",
    "                    print(f\"‚ûï Agregado '{subvalor.strip()}' a {categoria} (index {nuevo_index})\")\n",
    "\n",
    "    print(\"\\n‚úÖ Diccionarios actualizados.\")\n",
    "\n",
    "\n",
    "df = create_full_dataframe(username)\n",
    "if 'Weight' not in df.columns:\n",
    "    df['Weight'] = 0.0\n",
    "\n",
    "# üî• Aqu√≠ llamas\n",
    "actualizar_diccionarios(df)\n",
    "\n",
    "# üîß PASO: estandarizar valores mal escritos en la columna Brand\n",
    "def estandarizar_marcas(df, marca_objetivo=\"By Paola Ospina\"):\n",
    "    import unidecode\n",
    "    df[\"Brand\"] = df[\"Brand\"].astype(str).apply(lambda x: unidecode.unidecode(x.strip().lower()))\n",
    "    df[\"Brand\"] = df[\"Brand\"].apply(\n",
    "        lambda x: marca_objetivo if \"paola\" in x and \"ospina\" in x else x.title()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df = estandarizar_marcas(df)  # ‚úÖ llama la funci√≥n justo despu√©s de cargar df\n",
    "\n",
    "\n",
    "def get_base_state(df):\n",
    "    \"\"\"\n",
    "    Devuelve un vector de estado base (todo ceros) del mismo tama√±o que los vectores de prenda.\n",
    "    Se usa para representar el estado inicial del sistema.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"‚ùå DataFrame vac√≠o. No se puede calcular el tama√±o del vector base.\")\n",
    "    \n",
    "    first_image_id = df.iloc[0][\"Image_ID\"]\n",
    "    reference_vector = get_state_vector(first_image_id, df)\n",
    "    return [0] * len(reference_vector)\n",
    "     \n",
    "    \"\"\"\n",
    "    #_____________________________________________________\n",
    "    # üîπ Pedir el nombre del usuario din√°micamente\n",
    "    username = input(\"Ingrese su nombre de usuario: \").strip().lower()\n",
    "    \n",
    "    # Cargar el DataFrame final con el nombre ingresado\n",
    "    df = create_full_dataframe(username)\n",
    "    \n",
    "    # üîπ Asegurar que la columna 'Weight' existe antes de usarla\n",
    "    if 'Weight' not in df.columns:\n",
    "        df['Weight'] = 0.0  # Se inicializa en 0.0\n",
    "    \n",
    "    # Mostrar el DataFrame al usuario\n",
    "    from IPython.display import display\n",
    "    display(df)\n",
    "    \"\"\"\n",
    "#_____________________________________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "# Columnas para el archivo de categor√≠as\n",
    "CATEGORY_COLUMNS = [\"Image_ID\", \"Type\", \"Color\", \"Weather\", \"Style\", \"Occasion\"]\n",
    "\n",
    "# Funci√≥n para crear el archivo de categor√≠as si no existe\n",
    "def create_category_file(category_file):\n",
    "    if not os.path.exists(category_file):\n",
    "        df = pd.DataFrame(columns=CATEGORY_COLUMNS)\n",
    "        df.to_excel(category_file, index=False)\n",
    "        print(f\"üìÇ Archivo de categor√≠as creado: {category_file}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Archivo de categor√≠as encontrado: {category_file}\")\n",
    "\n",
    "# Llamar a la funci√≥n para asegurarnos de que el archivo existe\n",
    "# Obtener las rutas din√°micamente antes de llamar la funci√≥n\n",
    "user_folder, category_file = get_user_paths(username)\n",
    "\n",
    "\n",
    "# Llamar a la funci√≥n pasando el archivo de categor√≠as\n",
    "create_category_file(category_file)\n",
    "df = create_full_dataframe(username)\n",
    "if 'Weight' not in df.columns:\n",
    "    df['Weight'] = 0.0\n",
    "actualizar_diccionarios(df)\n",
    "\n",
    "####################################\n",
    "print(\"üìå Estado inicial del DataFrame despu√©s de cargarlo en create_full_dataframe:\")\n",
    "print(df.head())  # Debe mostrar datos\n",
    "\n",
    "#_________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "import requests\n",
    "\n",
    "# Tu clave de API de OpenWeatherMap\n",
    "API_KEY = \"b438ae6755885d7b6944a6dba68f9519\"  # üö® Reemplaza esto con tu clave real\n",
    "\n",
    "# Funci√≥n para obtener el clima actual en Bogot√°\n",
    "def get_weather():\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?q=Bogota,CO&appid={API_KEY}&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        temperature = data[\"main\"][\"temp\"]  # Temperatura actual en grados Celsius\n",
    "        weather_condition = data[\"weather\"][0][\"main\"]  # Ejemplo: \"Clear\", \"Rain\", \"Clouds\"\n",
    "        return temperature, weather_condition\n",
    "    else:\n",
    "        print(\"üö® Error al obtener los datos del clima.\")\n",
    "        return None, None\n",
    "\n",
    "# Obtener y mostrar el clima actual\n",
    "#temperature, weather_condition = get_weather()\n",
    "#print(f\"üå§Ô∏è Clima en Bogot√°: {temperature}¬∞C, {weather_condition}\")\n",
    "\n",
    "\n",
    "#_______________________________________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "\n",
    "# Inicializar Q-Table y par√°metros de aprendizaje reforzado Q learning\n",
    "q_table = {}  # Ahora almacenar√° claves tipo (tuple(state_vector), tuple(action_vector))\n",
    "alpha, gamma, epsilon, decay_rate = 0.1, 0.9, 1.0, 0.995\n",
    "feedback_db = []\n",
    "\n",
    "\n",
    "# Funci√≥n para guardar la Q-Table en Excel q learning\n",
    "def save_q_table():\n",
    "    if q_table:\n",
    "        df_qtable = pd.DataFrame([(str(k[0]), str(k[1]), v) for k, v in q_table.items()],\n",
    "                                 columns=[\"State\", \"Action\", \"Q-Value\"])\n",
    "        df_qtable.to_excel(q_table_path, index=False)\n",
    "        print(f\"‚úÖ Q-Table guardada con vectores en: {q_table_path}\")\n",
    "\n",
    "\n",
    "# Funci√≥n para cargar la Q-Table desde Excel\n",
    "def load_q_table():\n",
    "    global q_table\n",
    "    if os.path.exists(q_table_path):\n",
    "        df_qtable = pd.read_excel(q_table_path)\n",
    "        \n",
    "        if \"State\" in df_qtable.columns and \"Action\" in df_qtable.columns:\n",
    "            # Versi√≥n avanzada (con vectores de estado y acci√≥n)\n",
    "            q_table = {(eval(row[\"State\"]), eval(row[\"Action\"])): row[\"Q-Value\"] for _, row in df_qtable.iterrows()}\n",
    "            print(\"üîÑ Q-Table cargada con vectores (State, Action).\")\n",
    "        elif \"Outfit_IDs\" in df_qtable.columns and \"Q-Value\" in df_qtable.columns:\n",
    "            # Versi√≥n b√°sica (solo texto de combinaci√≥n)\n",
    "            print(\"‚ö†Ô∏è Q-Table actual solo contiene texto de outfits. No se puede reconstruir autom√°ticamente.\")\n",
    "            q_table = {}  # Vac√≠a para evitar error\n",
    "        else:\n",
    "            print(\"üö® Formato no reconocido en el archivo de Q-Table.\")\n",
    "\n",
    "# Llamamos a la carga de la Q-Table al iniciar el c√≥digo\n",
    "load_q_table()\n",
    "\n",
    "print(f\"üîÅ Q-Table cargada con {len(q_table)} combinaciones aprendidas.\")\n",
    "\n",
    "\n",
    "# Actualizar la Q-Table para ecuacion q learning\n",
    "def update_q_table_full_outfit(outfit, reward, df):\n",
    "    \"\"\"\n",
    "    Actualiza la Q-table usando todo el outfit como una acci√≥n completa.\n",
    "    El estado base es fijo (por ejemplo, un vector de ceros).\n",
    "    \"\"\"\n",
    "    base_state = tuple(get_base_state(df))\n",
    "    action_vector = []\n",
    "\n",
    "    for item in outfit:\n",
    "        vec = get_state_vector(item[\"Image_ID\"], df)\n",
    "        action_vector.extend(vec)\n",
    "\n",
    "    action_vector = tuple(action_vector)\n",
    "\n",
    "    current_q = q_table.get((base_state, action_vector), 0)\n",
    "    new_q = current_q + alpha * (reward - current_q)\n",
    "    q_table[(base_state, action_vector)] = new_q\n",
    "\n",
    "    save_q_table()\n",
    "\n",
    "\n",
    "# Generar outfits usando Q-Learning con combinaciones coherentes___________________________________________________________________________________\n",
    "# Asumiendo que ya tienes el feedback almacenado en feedback_db\n",
    "\n",
    "def adjust_recent_limit(feedback_db, recent_limit):\n",
    "    \"\"\"\n",
    "    Ajusta din√°micamente el l√≠mite de prendas recientes bas√°ndose en el feedback.\n",
    "    Si el usuario ha dado m√°s likes, aumenta el l√≠mite de prendas que pueden repetirse.\n",
    "    Si el feedback es negativo, disminuye el l√≠mite para evitar la repetici√≥n de prendas no gustadas.\n",
    "    \"\"\"\n",
    "    if not feedback_db:\n",
    "        return recent_limit  # Si no hay feedback, no ajustamos\n",
    "\n",
    "    # Calculamos la tasa de feedback positivo\n",
    "    positive_feedback = sum(1 for f in feedback_db if f['Reward'] == 1)\n",
    "    total_feedback = len(feedback_db)\n",
    "    success_rate = positive_feedback / total_feedback if total_feedback else 0\n",
    "\n",
    "    # Ajuste del l√≠mite basado en la tasa de √©xito del feedback\n",
    "    if success_rate > 0.7:  # Mucho feedback positivo\n",
    "        recent_limit = min(20, recent_limit + 1)  # Max 20 como ejemplo\n",
    "    elif success_rate < 0.3:  # Mucho feedback negativo\n",
    "        recent_limit = max(5, recent_limit - 1)  # Min 5 como ejemplo\n",
    "    else:\n",
    "        recent_limit = max(5, recent_limit)  # No dejar que baje de 5\n",
    "\n",
    "    print(f\"üß™ Nuevo l√≠mite de prendas recientes: {recent_limit} con tasa de √©xito del {success_rate*100:.2f}%\")\n",
    "    return recent_limit\n",
    "\n",
    "\n",
    "# Usar la funci√≥n en tu ciclo de generaci√≥n de outfits####################################################################################\n",
    "recent_combinations = []\n",
    "recent_limit = 10  # valor inicial, luego din√°mico seg√∫n feedback\n",
    "outfits generados\n",
    "#________________________________________________________________________________________________________________________________________\n",
    "# Numero de outfits generados\n",
    "def generate_outfits(num_outfits=3):\n",
    "    global evaluar_marca\n",
    "\n",
    "    outfits = []\n",
    "    attempts = 0\n",
    "    max_attempts = 200\n",
    "\n",
    "    df_available = df[df[\"Image\"].apply(os.path.exists)]\n",
    "\n",
    "    if evaluar_marca:\n",
    "        import unidecode\n",
    "        marca_normalizada = unidecode.unidecode(marca_objetivo.lower())\n",
    "        df_available[\"Brand_norm\"] = df_available[\"Brand\"].astype(str).apply(\n",
    "            lambda x: unidecode.unidecode(x.strip().lower())\n",
    "        )\n",
    "\n",
    "        prendas_marca = df_available[df_available[\"Brand_norm\"].str.contains(marca_normalizada, na=False)]\n",
    "\n",
    "        if prendas_marca.empty:\n",
    "            print(\"‚ö†Ô∏è No hay prendas de la marca disponibles. Se generar√°n outfits sin restricci√≥n de marca.\")\n",
    "            evaluar_marca = False\n",
    "\n",
    "        df_available.drop(columns=[\"Brand_norm\"], inplace=True)\n",
    "\n",
    "\n",
    "    outfit_types = [\n",
    "        ['Top', 'Bottom'],\n",
    "        ['Jacket', 'Top', 'Bottom'],\n",
    "        ['Jacket', 'Dress'],\n",
    "        ['Hoodie', 'Bottom'],\n",
    "        ['Hoodie', 'Dress']\n",
    "    ]\n",
    "\n",
    "    while len(outfits) < num_outfits and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        combo = random.choice(outfit_types)\n",
    "        outfit = []\n",
    "        tipos_necesarios = combo.copy()\n",
    "        used_ids = []\n",
    "\n",
    "        for tipo in tipos_necesarios:\n",
    "            candidatos = df_available[(df_available[\"Type\"] == tipo)]\n",
    "            candidatos = candidatos[~candidatos[\"Image_ID\"].isin(used_ids)]\n",
    "\n",
    "            if candidatos.empty:\n",
    "                break\n",
    "\n",
    "            prenda = candidatos.sample(1).iloc[0]\n",
    "            outfit.append(prenda.to_dict())\n",
    "            used_ids.append(prenda[\"Image_ID\"])\n",
    "\n",
    "        if len(outfit) != len(combo):\n",
    "            continue  # Outfit incompleto, lo descartamos\n",
    "\n",
    "        # üö´ Evitar repeticiones exactas\n",
    "        outfit_ids = tuple(sorted([p[\"Image_ID\"] for p in outfit]))\n",
    "        if outfit_ids in recent_combinations:\n",
    "            continue\n",
    "\n",
    "        # ‚úÖ Validar que haya al menos una prenda de la marca si se est√° evaluando\n",
    "        if evaluar_marca:\n",
    "            tiene_marca = any(p.get(\"Brand\") == marca_objetivo for p in outfit)\n",
    "            if not tiene_marca:\n",
    "                continue  # Outfit no cumple con la condici√≥n de la marca\n",
    "\n",
    "        # ‚úÖ Si pasa todas las validaciones, lo a√±adimos\n",
    "        outfits.append(outfit)\n",
    "        recent_combinations.append(outfit_ids)\n",
    "        if len(recent_combinations) > recent_limit:\n",
    "            recent_combinations.pop(0)\n",
    "\n",
    "    if not outfits:\n",
    "        print(\"‚ö†Ô∏è No se pudieron generar outfits variados con las prendas actuales.\")\n",
    "    return outfits\n",
    "\n",
    "#________________________________________________________________________________________________________________________________________\n",
    "\n",
    "# Mostrar outfits con im√°genes \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "def display_outfits(outfits, df):\n",
    "    \"\"\"\n",
    "    Muestra los outfits generados con las im√°genes reales y en orden:\n",
    "    Jacket ‚Üí Hoodie ‚Üí Top ‚Üí Bottom ‚Üí Dress.\n",
    "    Si falta una imagen, avisa cu√°l es y no la muestra.\n",
    "    \"\"\"\n",
    "    num_outfits = len(outfits)\n",
    "    max_layers = max(len(outfit) for outfit in outfits)\n",
    "    fig, axes = plt.subplots(max_layers, num_outfits, figsize=(12, 10), squeeze=False)\n",
    "\n",
    "    for col, outfit in enumerate(outfits):\n",
    "        image_ids = [item['Image_ID'] for item in outfit]\n",
    "        outfit_data = df[df['Image_ID'].isin(image_ids)].drop_duplicates(subset=['Image_ID'])\n",
    "\n",
    "        # Organizar las prendas en orden correcto\n",
    "        type_order = [\"Jacket\", \"Hoodie\", \"Top\", \"Bottom\", \"Dress\"]\n",
    "        ordered_outfit = []\n",
    "        for tipo in type_order:\n",
    "            prendas = outfit_data[outfit_data[\"Type\"] == tipo]\n",
    "            if not prendas.empty:\n",
    "                ordered_outfit.append(prendas.iloc[0])\n",
    "\n",
    "        # Mostrar las prendas\n",
    "        for row, item in enumerate(ordered_outfit):\n",
    "            image_path = item[\"Image\"]\n",
    "            image_id = item[\"Image_ID\"]\n",
    "            tipo = item[\"Type\"]\n",
    "            color = item[\"Color\"]\n",
    "            brand = item.get(\"Brand\", \"\")\n",
    "\n",
    "            if os.path.exists(image_path):\n",
    "                img = mpimg.imread(image_path)\n",
    "                axes[row, col].imshow(img)\n",
    "                if brand == \"By Paola Ospina\":\n",
    "                    axes[row, col].set_title(f\"{tipo} - {brand}\\n({color})\", fontsize=8)\n",
    "                else:\n",
    "                    axes[row, col].set_title(f\"{tipo} ({color})\", fontsize=9)\n",
    "\n",
    "\n",
    "            else:\n",
    "                axes[row, col].text(0.5, 0.5, f\"Sin Imagen\\nID: {image_id}\", ha='center', va='center', \n",
    "                                    fontsize=9, color='red')\n",
    "                axes[row, col].set_title(f\"{tipo}\", fontsize=9)\n",
    "                print(f\"üö® Imagen no encontrada para ID: {image_id} ‚Üí {image_path}\")\n",
    "\n",
    "            axes[row, col].axis('off')\n",
    "\n",
    "        # Ocultar filas vac√≠as si el outfit tiene menos capas\n",
    "        for empty_row in range(len(ordered_outfit), max_layers):\n",
    "            axes[empty_row, col].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#_________________________________________________________________________________________________________________________________________\n",
    "\n",
    "\n",
    "def get_next_state(action_vector, df):\n",
    "    \"\"\"\n",
    "    Selecciona el siguiente estado basado en la pol√≠tica de exploraci√≥n/explotaci√≥n\n",
    "    utilizando la Q-Table y los nuevos vectores de estado.\n",
    "    \"\"\"\n",
    "    possible_actions = df[\"Image_ID\"].values  # Lista de im√°genes disponibles\n",
    "\n",
    "    if not possible_actions.any():\n",
    "        return None  # No hay im√°genes para elegir\n",
    "\n",
    "    # Convertimos los Image_ID en vectores de estado\n",
    "    action_states = [get_state_vector(img_id, df) for img_id in possible_actions]\n",
    "\n",
    "    # Exploraci√≥n aleatoria si no hay datos en la Q-Table\n",
    "    if random.uniform(0, 1) < epsilon or not any((tuple(a) in q_table) for a in action_states):\n",
    "        return random.choice(action_states)\n",
    "\n",
    "    # Seleccionar la mejor acci√≥n basada en los valores Q\n",
    "    q_values = [q_table.get((tuple(action_vector), tuple(a)), 0) for a in action_states]\n",
    "    best_action = action_states[np.argmax(q_values)]\n",
    "\n",
    "    return best_action\n",
    "\n",
    "def registrar_feedback_detallado(outfit, reward, fuente, outfit_id, df, feedback_db):\n",
    "    \"\"\"\n",
    "    Guarda feedback detallado por cada prenda del outfit, incluyendo marca, tipo, color, y la fuente (Humano o Modelo).\n",
    "    \"\"\"\n",
    "    for prenda in outfit:\n",
    "        image_id = prenda.get('Image_ID')\n",
    "        fila = df[df[\"Image_ID\"] == image_id]\n",
    "\n",
    "        if fila.empty:\n",
    "            print(f\"‚ö†Ô∏è No se encontr√≥ la prenda con ID {image_id} en el DataFrame.\")\n",
    "            continue\n",
    "\n",
    "        fila = fila.iloc[0]\n",
    "        feedback_db.append({\n",
    "            'Outfit_ID': outfit_id,\n",
    "            'Image_ID': image_id,\n",
    "            'Type': fila.get('Type', 'Unknown'),\n",
    "            'Brand': fila.get('Brand', 'Unknown'),\n",
    "            'Color': fila.get('Color', 'Unknown'),\n",
    "            'Reward': reward,\n",
    "            'Fuente': fuente,\n",
    "            'Timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        })\n",
    "\n",
    "#___________________________________________\n",
    "def tasa_aceptacion_marca(feedback_input, marca_objetivo=\"By Paola Ospina\"):\n",
    "    \"\"\"\n",
    "    Calcula la tasa de aceptaci√≥n (likes) para una marca espec√≠fica.\n",
    "    Acepta tanto un DataFrame como una lista de diccionarios.\n",
    "    \"\"\"\n",
    "    # Convertir a DataFrame si es lista\n",
    "    if isinstance(feedback_input, list):\n",
    "        feedback_df = pd.DataFrame(feedback_input)\n",
    "    elif isinstance(feedback_input, pd.DataFrame):\n",
    "        feedback_df = feedback_input\n",
    "    else:\n",
    "        print(\"‚ùå Formato de feedback no v√°lido.\")\n",
    "        return 0.0\n",
    "\n",
    "    if feedback_df.empty:\n",
    "        print(\"üì≠ No hay feedback disponible.\")\n",
    "        return 0.0\n",
    "\n",
    "    prendas_marca = feedback_df[feedback_df[\"Brand\"] == marca_objetivo]\n",
    "    if prendas_marca.empty:\n",
    "        print(f\"‚ùó No hay feedback registrado para la marca {marca_objetivo}\")\n",
    "        return 0.0\n",
    "\n",
    "    positivos = (prendas_marca[\"Reward\"] == 1).sum()\n",
    "    tasa = positivos / len(prendas_marca)\n",
    "    print(f\"üíñ Tasa de aceptaci√≥n para '{marca_objetivo}': {tasa*100:.2f}%\")\n",
    "    return tasa\n",
    "\n",
    "# Recolectar feedback y actualizar la Q-Table q learning----------------------------------------\n",
    "def rate_outfits(outfits):\n",
    "    \"\"\"\n",
    "    Permite al usuario calificar cada outfit con 1 (Me gusta) o 0 (No me gusta) \n",
    "    y ajusta la Q-Table y el feedback detallado.\n",
    "    \"\"\"\n",
    "    global epsilon  \n",
    "\n",
    "    for idx, outfit in enumerate(outfits):\n",
    "        while True:\n",
    "            try:\n",
    "                rating = int(input(f\"üí¨ Califica el Outfit {idx + 1} {[item['Image_ID'] for item in outfit]} (1=Me gusta, 0=No me gusta): \"))\n",
    "                if rating not in [0, 1]:\n",
    "                    raise ValueError(\"Debes ingresar 1 o 0.\")\n",
    "                break\n",
    "            except ValueError as e:\n",
    "                print(e)\n",
    "\n",
    "        reward = 1 if rating == 1 else -1\n",
    "\n",
    "        # üîπ Guardar feedback detallado\n",
    "        registrar_feedback_detallado(outfit, reward, \"Humano\", idx + 1, df, feedback_db)\n",
    "        # üîπ NUEVO: Actualizar Q-Table con el outfit completo como acci√≥n\n",
    "        update_q_table_full_outfit(outfit, reward, df)\n",
    "\n",
    "        # üîπ Actualizar Q-Table por transiciones (state ‚Üí action)\n",
    "        for i in range(len(outfit) - 1):\n",
    "            state = outfit[i]['Image_ID']\n",
    "            action = outfit[i + 1]['Image_ID']\n",
    "\n",
    "            current_state_vector = get_state_vector(state, df)\n",
    "            next_state_vector = get_state_vector(action, df)\n",
    "            next_state = get_next_state(next_state_vector, df)\n",
    "\n",
    "            current_q = q_table.get((tuple(current_state_vector), tuple(next_state_vector)), 0)\n",
    "            max_next_q = max([\n",
    "                q_table.get((tuple(next_state), tuple(get_state_vector(a, df))), 0)\n",
    "                for a in df['Image_ID']\n",
    "            ], default=0)\n",
    "\n",
    "            new_q = current_q + alpha * (reward + gamma * max_next_q - current_q)\n",
    "            q_table[(tuple(current_state_vector), tuple(next_state_vector))] = new_q\n",
    "\n",
    "        # üîπ Ajustar pesos\n",
    "        for item in outfit:\n",
    "            if 'Image_ID' in item:\n",
    "                df.loc[df['Image_ID'] == item['Image_ID'], 'Weight'] += 0.1 if rating == 1 else -0.1\n",
    "                df['Weight'] = df['Weight'].clip(lower=0)\n",
    "\n",
    "    save_q_table()\n",
    "\n",
    "    # üîÅ Ajuste de exploraci√≥n/explotaci√≥n (epsilon)\n",
    "    total_feedback = len(feedback_db)\n",
    "    positive_feedback = sum(1 for f in feedback_db if f['Reward'] == 1)\n",
    "\n",
    "    if total_feedback > 0:\n",
    "        success_rate = positive_feedback / total_feedback\n",
    "        if success_rate > 0.7:\n",
    "            epsilon = max(0.1, epsilon * 0.95)\n",
    "        elif success_rate < 0.3:\n",
    "            epsilon = min(1.0, epsilon * 1.05)\n",
    "        else:\n",
    "            epsilon = max(0.1, epsilon * decay_rate)\n",
    "\n",
    "    print(f\"üîÑ Tasa de exploraci√≥n actualizada: Œµ = {epsilon:.4f}\")\n",
    "    save_params()  # üî• Guarda el epsilon actualizado\n",
    "    \n",
    "    # üíñ Mostrar tasa de aceptaci√≥n de la marca\n",
    "    tasa = tasa_aceptacion_marca(feedback_db, marca_objetivo)\n",
    "    print(f\"üíñ Tasa de aceptaci√≥n para '{marca_objetivo}': {tasa*100:.2f}%\")\n",
    "    \n",
    "\n",
    "###################################\n",
    "# Justo antes de usar df en generate_outfits()\n",
    "if df.empty:\n",
    "    print(\"üö® ERROR: df est√° vac√≠o antes de generar outfits.\")\n",
    "else:\n",
    "    print(\"‚úÖ df contiene datos antes de generar outfits:\")\n",
    "    print(df.head())\n",
    "\n",
    "#######################################\n",
    "\n",
    "### exportar DB\n",
    "from datetime import datetime\n",
    "\n",
    "def guardar_feedback_csv(feedback_db, ruta_csv):\n",
    "    feedback_df = pd.DataFrame(feedback_db)\n",
    "    fecha_actual = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    hora_actual = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    \n",
    "    global resumen_df\n",
    "    resumen_df = pd.DataFrame({\n",
    "        \"Descripci√≥n\": [\"Fecha de la sesi√≥n\", \"Hora de la sesi√≥n\", \"Total de interacciones\"],\n",
    "        \"Valor\": [fecha_actual, hora_actual, len(feedback_db)]\n",
    "    })\n",
    "\n",
    "    if not feedback_df.empty:\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        ruta_completa = ruta_csv.replace(\".csv\", f\"_{timestamp}.csv\")\n",
    "        feedback_df.to_csv(ruta_completa, index=False)\n",
    "        print(f\"üìÅ Feedback guardado como CSV en: {ruta_completa}\")\n",
    "\n",
    "#FEEDBACK ACUMULADO\n",
    "def cargar_feedback_acumulado(feedback_dir):\n",
    "    \"\"\"\n",
    "    Carga todos los archivos feedback_*.csv del usuario (hist√≥ricos y actuales),\n",
    "    los fusiona, elimina duplicados y devuelve un DataFrame √∫nico.\n",
    "    \"\"\"\n",
    "    feedback_files = glob.glob(os.path.join(feedback_dir, \"feedback_*.csv\"))\n",
    "    if not feedback_files:\n",
    "        print(\"üì≠ No hay archivos de feedback.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    lista_dfs = []\n",
    "    for archivo in feedback_files:\n",
    "        try:\n",
    "            df = pd.read_csv(archivo)\n",
    "            lista_dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error leyendo {archivo}: {e}\")\n",
    "\n",
    "    feedback_total = pd.concat(lista_dfs, ignore_index=True)\n",
    "    feedback_total.drop_duplicates(subset=[\"Outfit_ID\", \"Image_ID\", \"Timestamp\"], inplace=True)\n",
    "    print(f\"üì¶ Feedback acumulado cargado: {len(feedback_total)} entradas √∫nicas.\")\n",
    "    return feedback_total\n",
    "\n",
    "\n",
    "#######################################\n",
    "\n",
    "# Ciclo principal de evaluaci√≥n de outfits\n",
    "# Evaluaci√≥n de outfits\n",
    "def evaluate_outfits():\n",
    "    global recent_limit  # Importante: para poder modificar la variable global\n",
    "    while True:\n",
    "        outfits = generate_outfits(num_outfits=5)####################################################################################################\n",
    "\n",
    "        if not outfits:\n",
    "            print(\"üö® No se generaron outfits.\")\n",
    "            continue  \n",
    "\n",
    "        display_outfits(outfits, df)\n",
    "        rate_outfits(outfits)\n",
    "\n",
    "\n",
    "        # Aqu√≠ ajustamos recent_limit din√°micamente despu√©s del feedback del usuario\n",
    "        recent_limit = adjust_recent_limit(feedback_db, recent_limit)\n",
    "\n",
    "        if input(\"¬øQuieres evaluar m√°s outfits? (s/n): \").strip().lower() != 's':\n",
    "            print(\"Gracias por evaluar los outfits. ¬°Hasta luego!\")\n",
    "            break\n",
    "\n",
    "\n",
    "# Cargar feedback del usuario actual desde su carpeta\n",
    "feedback_files = glob.glob(os.path.join(feedback_dir, \"feedback_*.csv\"))  # üß† Ya apunta a la carpeta del usuario\n",
    "\n",
    "if feedback_files:\n",
    "    # üîÑ Cargar todos los CSVs de feedback encontrados\n",
    "    dfs = [pd.read_csv(f) for f in feedback_files]\n",
    "    feedback_hist = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    print(f\"üìà Feedback hist√≥rico cargado: {len(feedback_hist)} interacciones (antes de limpieza).\")\n",
    "\n",
    "    # üßº Eliminar duplicados basados en Outfit, Imagen y Timestamp\n",
    "    feedback_hist.drop_duplicates(subset=[\"Outfit_ID\", \"Image_ID\", \"Timestamp\"], inplace=True)\n",
    "\n",
    "    print(f\"‚úÖ Feedback √∫nico conservado: {len(feedback_hist)} entradas tras limpieza.\")\n",
    "\n",
    "    # üîÅ Asignar a la base actual\n",
    "    feedback_db = feedback_hist.to_dict('records')\n",
    "else:\n",
    "    print(\"üì≠ No se encontr√≥ feedback previo del usuario.\")\n",
    "\n",
    "\n",
    "if feedback_files:\n",
    "    # üîÑ Cargar todos los CSVs de feedback encontrados\n",
    "    dfs = [pd.read_csv(f) for f in feedback_files]\n",
    "    feedback_hist = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    print(f\"üìà Feedback hist√≥rico cargado: {len(feedback_hist)} interacciones (antes de limpieza).\")\n",
    "\n",
    "    # üßº Eliminar duplicados basados en Outfit, Imagen y Timestamp\n",
    "    feedback_hist.drop_duplicates(subset=[\"Outfit_ID\", \"Image_ID\", \"Timestamp\"], inplace=True)\n",
    "\n",
    "    print(f\"‚úÖ Feedback √∫nico conservado: {len(feedback_hist)} entradas tras limpieza.\")\n",
    "\n",
    "    # üîÅ Asignar a la base actual\n",
    "    feedback_db = feedback_hist.to_dict('records')\n",
    "\n",
    "# Ejecutar el sistema de recomendaci√≥n\n",
    "evaluate_outfits()\n",
    "\n",
    "# Guardar feedback como CSV\n",
    "ruta_feedback_csv = os.path.join(feedback_dir, \"feedback.csv\")\n",
    "guardar_feedback_csv(feedback_db, ruta_feedback_csv)\n",
    "\n",
    "def contar_outfits_totales(ruta_feedback_csv):\n",
    "    \"\"\"\n",
    "    Cuenta cu√°ntos outfits √∫nicos se han registrado en feedback.csv\n",
    "    \"\"\"\n",
    "    if not os.path.exists(ruta_feedback_csv):\n",
    "        print(\"üì≠ No existe feedback.csv a√∫n.\")\n",
    "        return 0\n",
    "    df = pd.read_csv(ruta_feedback_csv)\n",
    "    total = df['Outfit_ID'].nunique()\n",
    "    print(f\"üìä Total de outfits generados y guardados: {total}\")\n",
    "    return total\n",
    "\n",
    "\n",
    "\n",
    "def plot_learning_curve(guardar_imagen=False, ruta_imagen=None):\n",
    "    \"\"\"\n",
    "    Genera la curva de aprendizaje basada en la recompensa acumulada.\n",
    "    Agrega una curva suavizada (rolling mean) y anota el punto m√°ximo.\n",
    "    Puede guardar la imagen si se desea.\n",
    "    \"\"\"\n",
    "    if not feedback_db:\n",
    "        print(\"‚ö†Ô∏è No hay feedback disponible para graficar la curva de aprendizaje.\")\n",
    "        return\n",
    "\n",
    "    # Crear DataFrame ordenado\n",
    "    df_feedback = pd.DataFrame(feedback_db)\n",
    "    df_feedback[\"Timestamp\"] = pd.to_datetime(df_feedback[\"Timestamp\"])\n",
    "    df_feedback = df_feedback.sort_values(\"Timestamp\").reset_index(drop=True)\n",
    "\n",
    "    # üîπ Agregar n√∫mero de iteraci√≥n y recompensa acumulada\n",
    "    df_feedback[\"Iteraci√≥n\"] = df_feedback.index\n",
    "    df_feedback[\"Recompensa Acumulada\"] = df_feedback[\"Reward\"].cumsum()\n",
    "\n",
    "    # üîπ Suavizar la curva con media m√≥vil\n",
    "    df_feedback[\"Tendencia\"] = df_feedback[\"Recompensa Acumulada\"].rolling(window=10).mean()\n",
    "\n",
    "    # üîπ Plot principal\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df_feedback[\"Iteraci√≥n\"], df_feedback[\"Recompensa Acumulada\"],\n",
    "             color='darkblue', marker='o', linewidth=2, label=\"Recompensa acumulada\")\n",
    "\n",
    "    # üîπ A√±adir curva suavizada\n",
    "    plt.plot(df_feedback[\"Iteraci√≥n\"], df_feedback[\"Tendencia\"],\n",
    "             color='orange', linestyle='--', linewidth=2, label=\"Tendencia (media m√≥vil)\")\n",
    "\n",
    "    # üîπ Anotar punto m√°ximo\n",
    "    max_idx = df_feedback[\"Recompensa Acumulada\"].idxmax()\n",
    "    max_val = df_feedback.loc[max_idx]\n",
    "    plt.annotate(\"üéØ M√°ximo\",\n",
    "                 xy=(max_val[\"Iteraci√≥n\"], max_val[\"Recompensa Acumulada\"]),\n",
    "                 xytext=(max_val[\"Iteraci√≥n\"] + 10, max_val[\"Recompensa Acumulada\"] + 5),\n",
    "                 arrowprops=dict(arrowstyle=\"->\", color='gray'))\n",
    "\n",
    "    # üîπ Etiquetas y estilos\n",
    "    plt.title(\"üìà Curva de Aprendizaje del Sistema\")\n",
    "    plt.xlabel(\"Iteraci√≥n\")\n",
    "    plt.ylabel(\"Recompensa acumulada\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    if guardar_imagen and ruta_imagen:\n",
    "        plt.savefig(ruta_imagen, bbox_inches='tight')\n",
    "        print(f\"üñºÔ∏è Curva de aprendizaje guardada como imagen en: {ruta_imagen}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Llamar a la funci√≥n de visualizaci√≥n despu√©s de evaluar los outfits\n",
    "plot_learning_curve()\n",
    "\n",
    "\n",
    "### ACEPTACION DE MARCA Y CURVA DEL DIA--------------------------------------------------------------------------------\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Ruta base donde guardas el feedback\n",
    "feedback_dir = r\"C:\\Users\\POspina\\OneDrive - SLB\\Desktop\\Backup\\Tesis\\OUTPUT_CODIGO\"\n",
    "feedback_files = glob.glob(os.path.join(feedback_dir, \"feedback_*.csv\"))\n",
    "\n",
    "# Obtener el archivo m√°s reciente\n",
    "ruta_feedback = max(feedback_files, key=os.path.getctime)\n",
    "print(f\"üìÇ Cargando archivo m√°s reciente: {ruta_feedback}\")\n",
    "# Cargar el feedback m√°s reciente como DataFrame\n",
    "feedback_df = pd.read_csv(ruta_feedback)\n",
    "feedback_df[\"Timestamp\"] = pd.to_datetime(feedback_df[\"Timestamp\"], errors='coerce')\n",
    "feedback_df[\"Fecha\"] = feedback_df[\"Timestamp\"].dt.date\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ‚úÖ 2. GR√ÅFICO DE ACEPTACI√ìN POR OUTFIT (% de likes por Outfit_ID)\n",
    "# -----------------------------------------------------------------------------\n",
    "aceptacion_por_outfit = feedback_df.groupby(\"Outfit_ID\")[\"Reward\"].mean() * 100\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(aceptacion_por_outfit.index.astype(str), aceptacion_por_outfit.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"üí¨ Porcentaje de aceptaci√≥n por outfit\")\n",
    "plt.ylabel(\"% Me gusta\")\n",
    "plt.xlabel(\"Outfit ID\")\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# üëó 3. TOP PRENDAS M√ÅS LIKED ‚Äì GENERAL\n",
    "# -----------------------------------------------------------------------------\n",
    "likes = feedback_df[feedback_df[\"Reward\"] == 1]\n",
    "top_general = likes.groupby([\"Image_ID\", \"Type\", \"Brand\"]).size().reset_index(name=\"Likes\")\n",
    "top_general = top_general.sort_values(\"Likes\", ascending=False).head(10)\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Filtrar prendas con reward positivo\n",
    "likes_df = feedback_df[feedback_df[\"Reward\"] == 1]\n",
    "\n",
    "# Contar likes por Image_ID\n",
    "top_likes = likes_df.groupby(\"Image_ID\").size().sort_values(ascending=False).head(5).reset_index(name=\"Likes\")\n",
    "\n",
    "# Unir con df para obtener ruta de imagen y detalles\n",
    "top_with_images = top_likes.merge(df[[\"Image_ID\", \"Image\", \"Brand\", \"Type\", \"Color\"]], on=\"Image_ID\", how=\"left\")\n",
    "\n",
    "# Mostrar im√°genes de las prendas m√°s liked\n",
    "fig, axes = plt.subplots(1, len(top_with_images), figsize=(15, 4))\n",
    "\n",
    "for i, (_, row) in enumerate(top_with_images.iterrows()):\n",
    "    img_path = row[\"Image\"]\n",
    "    try:\n",
    "        img = mpimg.imread(img_path)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'ID {row[\"Image_ID\"]}\\n{row[\"Type\"]} - {row[\"Likes\"]} Likes', fontsize=8)\n",
    "    except Exception:\n",
    "        axes[i].text(0.5, 0.5, \"‚ùå Imagen no encontrada\", ha='center', va='center', fontsize=9)\n",
    "        axes[i].set_title(f'ID {row[\"Image_ID\"]}', fontsize=9)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# PRENDAS BY PAOLA OSPINA\n",
    "Para este codigo pongo las 3 mas gustadas?\n",
    "\n",
    "# üéÄ Mostrar top prendas m√°s liked de la marca \"By Paola Ospina\"\n",
    "likes_marca = feedback_df[(feedback_df[\"Reward\"] == 1) & (feedback_df[\"Brand\"] == \"By Paola Ospina\")]\n",
    "top_marca_likes = likes_marca.groupby(\"Image_ID\").size().sort_values(ascending=False).head(3).reset_index(name=\"Likes\")#.head cantidad de prendas eneste caso las 3 mas gustadas\n",
    "top_marca_images = top_marca_likes.merge(df[[\"Image_ID\", \"Image\", \"Brand\", \"Type\", \"Color\"]], on=\"Image_ID\", how=\"left\")\n",
    "\n",
    "if not top_marca_images.empty:\n",
    "    fig, axes = plt.subplots(1, len(top_marca_images), figsize=(15, 4))\n",
    "    for i, (_, row) in enumerate(top_marca_images.iterrows()):\n",
    "        img_path = row[\"Image\"]\n",
    "        try:\n",
    "            img = mpimg.imread(img_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].axis('off')\n",
    "            axes[i].set_title(f'{row[\"Type\"]}\\n{row[\"Likes\"]} Likes', fontsize=8)\n",
    "        except Exception:\n",
    "            axes[i].text(0.5, 0.5, \"‚ùå Imagen no encontrada\", ha='center', va='center')\n",
    "            axes[i].axis('off')\n",
    "    plt.suptitle(\"‚ú® Top prendas de 'By Paola Ospina'\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è A√∫n no hay prendas de la marca con likes registrados.\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# üëó 4. TOP PRENDAS DE LA MARCA 'By Paola Ospina'\n",
    "# -----------------------------------------------------------------------------\n",
    "top_marca = top_general[top_general[\"Brand\"] == \"By Paola Ospina\"].head(5)\n",
    "\n",
    "if not top_marca.empty:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(top_marca[\"Image_ID\"].astype(str), top_marca[\"Likes\"], color='lightgreen')\n",
    "    plt.title(\"‚ú® Prendas m√°s liked de 'By Paola Ospina'\")\n",
    "    plt.xlabel(\"Image_ID\")\n",
    "    plt.ylabel(\"Likes\")\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùó A√∫n no hay prendas de la marca con likes registrados.\")\n",
    "\n",
    "\n",
    "# ====================== M√âTRICAS Y KPIs ==========================\n",
    "\n",
    "def calcular_precision(feedback_db):\n",
    "    if not feedback_db:\n",
    "        return 0\n",
    "    total = len(feedback_db)\n",
    "    positivos = sum(1 for f in feedback_db if f['Reward'] == 1)\n",
    "    precision = positivos / total\n",
    "    print(f\"üéØ Precisi√≥n del modelo: {precision * 100:.2f}%\")\n",
    "    return precision\n",
    "\n",
    "\n",
    "def calcular_satisfaccion(feedback_db):\n",
    "    if not feedback_db:\n",
    "        return 0\n",
    "    positivos = sum(1 for f in feedback_db if f['Reward'] == 1)\n",
    "    satisfaction = positivos / len(feedback_db)\n",
    "    print(f\"üòä Satisfacci√≥n del usuario: {satisfaction * 100:.2f}%\")\n",
    "    return satisfaction\n",
    "\n",
    "def mostrar_prendas_populares(df):\n",
    "    print(\"\\nüëó Prendas m√°s usadas:\")\n",
    "    print(df.sort_values(\"Weight\", ascending=False)[[\"Image_ID\", \"Type\", \"Color\", \"Weight\"]].head(5))\n",
    "\n",
    "    print(\"\\nüß• Prendas menos usadas:\")\n",
    "    print(df.sort_values(\"Weight\")[[\"Image_ID\", \"Type\", \"Color\", \"Weight\"]].head(5))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def graficar_colores_populares(df):\n",
    "    color_counts = df['Color'].str.split(', ').explode().value_counts()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    color_counts.plot(kind='bar')\n",
    "    plt.title(\"üé® Colores m√°s frecuentes en el sistema\")\n",
    "    plt.ylabel(\"Cantidad de prendas\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- KPIs del Sistema ---\")\n",
    "calcular_precision(feedback_db)\n",
    "calcular_satisfaccion(feedback_db)\n",
    "tasa_aceptacion_marca(feedback_db, marca_objetivo)\n",
    "#mostrar_prendas_populares(df)\n",
    "#graficar_colores_populares(df)\n",
    "\n",
    "\n",
    "def guardar_kpis_en_excel(feedback_db, df, ruta_salida):\n",
    "    precision = calcular_precision(feedback_db)\n",
    "    satisfaccion = calcular_satisfaccion(feedback_db)\n",
    "    aceptacion_marca = tasa_aceptacion_marca(feedback_db, marca_objetivo)\n",
    "\n",
    "    # Prendas m√°s y menos usadas\n",
    "    top_usadas = df.sort_values(\"Weight\", ascending=False)[[\"Image_ID\", \"Type\", \"Color\", \"Weight\"]].head(5)\n",
    "    menos_usadas = df.sort_values(\"Weight\")[[\"Image_ID\", \"Type\", \"Color\", \"Weight\"]].head(5)\n",
    "\n",
    "    # Guardar todo en un Excel con m√∫ltiples hojas\n",
    "    with pd.ExcelWriter(ruta_salida) as writer:\n",
    "        # ‚úÖ CORRECTO: ahora todo est√° dentro del with\n",
    "        kpi_df = pd.DataFrame([\n",
    "            {\"M√©trica\": \"Precisi√≥n\", \"Valor\": f\"{precision:.2%}\"},\n",
    "            {\"M√©trica\": \"Satisfacci√≥n\", \"Valor\": f\"{satisfaccion:.2%}\"},\n",
    "            {\"M√©trica\": f\"Aceptaci√≥n '{marca_objetivo}'\", \"Valor\": f\"{aceptacion_marca:.2%}\"}\n",
    "        ])\n",
    "        kpi_df.to_excel(writer, sheet_name=\"KPIs\", index=False)\n",
    "\n",
    "        top_usadas.to_excel(writer, sheet_name=\"M√°s usadas\", index=False)\n",
    "        menos_usadas.to_excel(writer, sheet_name=\"Menos usadas\", index=False)\n",
    "\n",
    "        print(f\"üìÇ KPIs guardados exitosamente en: {ruta_salida}\")\n",
    "\n",
    "\n",
    "# Guardar KPIs en un archivo de Excel\n",
    "guardar_kpis_en_excel(feedback_db, df, ruta_kpis)\n",
    "\n",
    "#CURVA D EAPRENDIZAJE POR OUTFIT \n",
    "def plot_learning_curve_por_outfit(feedback_db):\n",
    "    \"\"\"\n",
    "    üìà Nueva curva de aprendizaje basada en evaluaciones por Outfit_ID (no por prenda individual).\n",
    "    \"\"\"\n",
    "    if not feedback_db:\n",
    "        print(\"‚ö†Ô∏è No hay feedback disponible para graficar la curva por outfit.\")\n",
    "        return\n",
    "\n",
    "    # Crear DataFrame\n",
    "    df_feedback = pd.DataFrame(feedback_db)\n",
    "    df_feedback[\"Timestamp\"] = pd.to_datetime(df_feedback[\"Timestamp\"])\n",
    "    df_feedback = df_feedback.sort_values(\"Timestamp\").reset_index(drop=True)\n",
    "\n",
    "    # Agrupar por Outfit_ID y tomar el reward promedio (asumiendo que el usuario eval√∫a el outfit completo)\n",
    "    outfit_feedback = df_feedback.groupby(\"Outfit_ID\")[\"Reward\"].mean().reset_index()\n",
    "\n",
    "    # C√°lculo de recompensa acumulada por Outfit\n",
    "    outfit_feedback[\"Iteraci√≥n\"] = outfit_feedback.index\n",
    "    outfit_feedback[\"Recompensa Acumulada\"] = outfit_feedback[\"Reward\"].cumsum()\n",
    "\n",
    "    # üîπ Suavizado\n",
    "    outfit_feedback[\"Tendencia\"] = outfit_feedback[\"Recompensa Acumulada\"].rolling(window=5).mean()\n",
    "\n",
    "    # üîπ Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(outfit_feedback[\"Iteraci√≥n\"], outfit_feedback[\"Recompensa Acumulada\"],\n",
    "             color='green', marker='o', linewidth=2, label=\"Recompensa acumulada por outfit\")\n",
    "\n",
    "\n",
    "    plt.title(\"üìà Curva de Aprendizaje Basada en Outfits\")\n",
    "    plt.xlabel(\"Outfit evaluado\")\n",
    "    plt.ylabel(\"Recompensa acumulada\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def calcular_aceptacion_marca(feedback_db, marca_objetivo=\"By Paola Ospina\"):\n",
    "    if not feedback_db:\n",
    "        return 0.0\n",
    "    marca_feedback = [f for f in feedback_db if f.get(\"Brand\") == marca_objetivo]\n",
    "    if not marca_feedback:\n",
    "        return 0.0\n",
    "    positivos = sum(1 for f in marca_feedback if f['Reward'] == 1)\n",
    "    return positivos / len(marca_feedback)\n",
    "\n",
    "\n",
    "# DAHSBOARD #_######################################\n",
    "def exportar_dashboard_completo(df, q_table, feedback_db, ruta_excel, ruta_imagen=None):\n",
    "    # Convertir Q-table en DataFrame\n",
    "    q_df = pd.DataFrame([(k[0], k[1], v) for k, v in q_table.items()],\n",
    "                        columns=[\"State\", \"Action\", \"Q-Value\"])\n",
    "    q_df = q_df.sort_values(\"Q-Value\", ascending=False).head(50)\n",
    "\n",
    "    # KPIs\n",
    "    precision = calcular_precision(feedback_db)\n",
    "    satisfaccion = calcular_satisfaccion(feedback_db)\n",
    "    aceptacion_marca = tasa_aceptacion_marca(feedback_db, marca_objetivo)\n",
    "    total_interacciones = len(feedback_db)\n",
    "\n",
    "\n",
    "    kpi_df = pd.DataFrame({\n",
    "        \"M√©trica\": [\"Precisi√≥n\", \"Satisfacci√≥n\", f\"Aceptaci√≥n '{marca_objetivo}'\", \"Total de Interacciones\"],\n",
    "        \"Valor\": [f\"{precision:.2%}\", f\"{satisfaccion:.2%}\", f\"{aceptacion_marca:.2%}\", total_interacciones]\n",
    "    })\n",
    "\n",
    "\n",
    "    top_usadas = df.sort_values(\"Weight\", ascending=False)[[\"Image_ID\", \"Type\", \"Color\", \"Weight\"]].head(5)\n",
    "    menos_usadas = df.sort_values(\"Weight\")[[\"Image_ID\", \"Type\", \"Color\", \"Weight\"]].head(5)\n",
    "    feedback_df = pd.DataFrame(feedback_db)\n",
    "\n",
    "    with pd.ExcelWriter(ruta_excel, engine='xlsxwriter') as writer:\n",
    "        kpi_df.to_excel(writer, sheet_name=\"KPIs\", index=False)\n",
    "        top_usadas.to_excel(writer, sheet_name=\"M√°s Usadas\", index=False)\n",
    "        menos_usadas.to_excel(writer, sheet_name=\"Menos Usadas\", index=False)\n",
    "        q_df.to_excel(writer, sheet_name=\"Q-Table\", index=False)\n",
    "        feedback_df.to_excel(writer, sheet_name=\"Feedback\", index=False)\n",
    "\n",
    "        # Insertar imagen si existe\n",
    "        if ruta_imagen and os.path.exists(ruta_imagen):\n",
    "            workbook = writer.book\n",
    "            worksheet = workbook.add_worksheet(\"Curva Aprendizaje\")\n",
    "            writer.sheets[\"Curva Aprendizaje\"] = worksheet\n",
    "            worksheet.insert_image(\"B2\", ruta_imagen)\n",
    "\n",
    "        resumen_df.to_excel(writer, sheet_name=\"Resumen\", index=False)\n",
    "        \n",
    "        print(f\"üìä Dashboard exportado exitosamente en: {ruta_excel}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e02e085-8097-41a9-bf21-d84c6151d2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
